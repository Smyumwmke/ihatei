视频事件的分析与理解 PDF下载 裴明涛，赵猛著 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#756826819
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#756826819
<p>书名:视频事件的分析与理解</p><p>作者:裴明涛，赵猛著</p><p>页数:215页</p><p>定价:¥62.0</p><p>出版社:北京理工大学出版社</p><p>出版日期:2019-03-01</p><p>ISBN:9787568268196</p><p><h2>本书特色</h2></p>[<p>
视频事件的分析与理解是计算机视觉领域的重要研究内容之一，具有重要的理论研究意义和实际应用价值。本书首先介绍了视频事件分析与理解所涉及的目标检测、目标跟踪以及事件识别的研究现状，分析了视频事件分析与理解中的关键问题，然后重点介绍了作者研究团队在视频事件分析与理解领域的研究工作和成果。<br/>本书可供计算机、自动化、模式识别等领域的科研人员参考，也可作为高等院校计算机、自动化、电子信息等专业的教学参考书。
                                        </p>]<p><h2>内容简介</h2></p>[<p>视频事件的分析与理解由于其在智能监控, 智能人机交互等领域有着广泛的应用前景, 成为计算机视觉领域备受关注的前沿方向之一。本书详细介绍了作者近年来在视频事件分析与理解方面所作的工作, 主要包括以下三个方面的内容: 场景中的物体检测方法研究 ; 视频中的目标跟踪方法研究 ; 基于时序与或图的视频事件分析与理解方法。</p>]<p><h2>作者简介</h2></p>[<p>裴明涛，男，博士，副教授，博士生导师。2004年获得北京理工大学计算机应用技术博士学位，并进入北京理工大学计算机学院工作至今；2009年至2011年在美国加州大学洛杉矶分校进行访问研究。
科研方向为计算机视觉，人工智能以及模式识别，主持国家自然科学基金、国家973项目子课题等科研项目十余项。在计算机视觉与人工智能顶级国际会议ICCV, AAAI以及SCI收录国际重要学术期刊IEEE TIP、 IEEE TMM、 IEEE TITS、CVIU、PR上发表多篇论文。</p>]<p><h2>目录</h2></p>
    第1章  引言        1.1    视频事件分析与理解的背景和意义        1.2    目标检测的研究现状          1.2.1  基于HOG/SVM的行人检测          1.2.2  基于可变形部件模型的行人检测          1.2.3  基于深度神经网络的行人检测          1.2.4  基于特征融合的行人检测          1.2.5  行人检测中的分类器          1.2.6  行人检测数据集        1.3    目标跟踪的研究现状          1.3.1  目标表示          1.3.2  统计建模          1.3.3  目标跟踪数据集        1.4    视频事件分析与理解的研究现状          1.4.1  视频事件中的相关术语          1.4.2  视频事件的特征表示          1.4.3  视频事件的建模方法          1.4.4  视频事件数据集        1.5    关于本书      第2章  视频中的目标检测算法        2.1    基于深度通道特征的行人检测方法          2.1.1  深度卷积神经网络与稀疏滤波          2.1.2  深度通道特征          2.1.3  深度通道特征的提取          2.1.4  基于深度通道特征的行人检测          2.1.5  实验结果        2.2    基于特征共享和联合Boosting方法的物体检测方法          2.2.1  基于滑动窗口和二分类器的物体检测框架          2.2.2  二分类Boosting方法          2.2.3  共享特征与多分类Boosting方法          2.2.4  实验结果        2.3    本章小结      第3章  视频中的目标跟踪算法        3.1    基于多分量可变部件模型的行人跟踪方法          3.1.1  行人可变部件模型及其初始化          3.1.2  多分量可变部件模型          3.1.3  基于多分量可变部件模型的跟踪算法          3.1.4  自顶向下与自底向上相结合的跟踪框架          3.1.5  实验结果        3.2    基于锚点标签传播的物体跟踪方法          3.2.1  问题描述          3.2.2  求解*优H          3.2.3  求解软标签预测矩阵A          3.2.4  软标签传播          3.2.5  基于标签传播模型的跟踪算法          3.2.6  实验结果        3.3    本章小结      第4章  事件时序与或图模型的学习        4.1    事件模型的定义          4.1.1  一元和二元关系          4.1.2  原子动作          4.1.3  时序与或图模型          4.1.4  子节点之间的时序关系          4.1.5  解析图        4.2    事件模型的学习          4.2.1  一元和二元关系的检测          4.2.2  原子动作的学习          4.2.3  事件模型的学习        4.3    实验结果          4.3.1  实验数据          4.3.2  时序与或图学习结果          4.3.3  所学的模型有益于场景语义的识别        4.4    本章小结      第5章  基于时序与或图模型的视频事件解析        5.1    时序与或图与随机上下文相关文法        5.2    Earley在线解析算法        5.3    改进的Earley解析算法        5.4    事件解析的定义        5.5    对事件的解析        5.6    实验          5.6.1  原子动作识别          5.6.2  事件解析          5.6.3  意图预测          5.6.4  事件补全        5.7    本章小结      第6章  基于关键原子动作和上下文信息的事件解析        6.1    基于关键原子动作的事件解析          6.1.1  原子动作权值的学习          6.1.2  带有原子动作权值的事件解析图          6.1.3  基于原子动作权值的事件可识别度          6.1.4  实验结果        6.2    基于社会角色的事件分析          6.2.1  相关工作          6.2.2  角色建模与推断          6.2.3  基于角色的事件识别          6.2.4  实验结果        6.3    基于群体和环境上下文的事件识别          6.3.1  相关工作          6.3.2  基于场景上下文的事件识别          6.3.3  基于群体上下文的事件识别          6.3.4  基于场景和群体上下文的事件识别          6.3.5  实验结果        6.4    本章小结      参考文献
