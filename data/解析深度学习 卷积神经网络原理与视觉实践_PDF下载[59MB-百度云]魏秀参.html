解析深度学习:卷积神经网络原理与视觉实践 PDF下载 魏秀参 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712134528
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#712134528
<p>书名:解析深度学习:卷积神经网络原理与视觉实践</p><p>作者:魏秀参</p><p>页数:200</p><p>定价:¥79.0</p><p>出版社:电子工业出版社</p><p>出版日期:2018-01-01</p><p>ISBN:9787121345289</p><p><h2>本书特色</h2></p>[<p>
 适读人群 ：人工智能领域的从业者及对此方向有兴趣的人群<br/>   《解析深度学习：卷积神经网络原理与视觉实践》是对治深度学习恐惧症的一剂良药。作者魏秀参博士，毕业于著名的南京大学LAMDA研究所，现为旷视科技南京研究院负责人。本书凝聚了他多年的功力，集原理与实践于一体，将卷积神经网络这颗仙丹炼得出神入化，以此攻克计算机视觉实践中的一个又一个难题。 <br/>全书没有佶屈聱牙的文字、没有艰涩难懂的术语，只有明明白白的道理、由浅入深的论证、清晰流畅的架构。在内容的安排上，兼顾了基础知识和学习难点，各有侧重，让初学者不仅可以看明白、而且能够读懂，知其所以然并举一反三运用到自己的工程实践中。 <br/>无怪乎，业内专家认为“本书可能是我知道的“醉”好的深度学习的中文入门教材”。 <br/>
</p>]<p><h2>内容简介</h2></p>[<p>深度学习，特别是深度卷积神经网络是人工智能的重要分支领域，卷积神经网络技术也被广泛应用于各种现实场景，在许多问题上都取得了超越人类智能的结果。本书作为该领域的入门书籍，在内容上涵盖深度卷积神经网络的基础知识和实践应用两大方面。全书共14 章，分为三个部分：靠前部分为绪论；第二部分（～4 章）介绍卷积神经网络的基础知识、基本部件、经典结构和模型压缩等基础理论内容；第三部分（第5～14 章）介绍深度卷积神经网络自数据准备开始，到模型参数初始化、不同网络部件的选择、网络配置、网络模型训练、不平衡数据处理，很终到模型集成等实践应用技巧和经验。本书并不是一本编程类书籍，而是希望通过“基础知识”和“实践技巧”两方面使读者从更高维度了解、掌握并成功构建针对自身应用问题的深度卷积神经网络。本书可作为深度学习和卷积神经网络爱好者的入门书籍，也可供没有机器学习背景但希望能快速掌握该方面知识并将其应用于实际问题的各行从业者阅读参考。</p>]<p><h2>作者简介</h2></p>[<p>魏秀参 ，旷视科技（Face++）南京研究院负责人。南京大学LAMDA研究所博士，主要研究领域为计算机视觉和机器学习。在相关领域重要国际期刊和国际会议发表论文十余篇，并两次获得国际计算机视觉相关竞赛冠、亚军。曾获CVPR 2017佳审稿人、南京大学博士生校长特别奖学金等荣誉，担任ICCV、CVPR、ECCV、NIPS、IJCAI、AAAI等国际会议PC member。（个人自媒体：知乎“魏秀参”，新浪微博“Wilson_NJUer”）</p>]<p><h2>目录</h2></p>
**部分绪论1 0.1 引言  . 2 0.2 什么是深度学习  3 0.3 深度学习的前世今生  . 6 第二部分基础理论篇9 1 卷积神经网络基础知识10 1.1 发展历程  11 1.2 基本结构  13 1.3 前馈运算  16 1.4 反馈运算  16 1.5 小结  . 19 2 卷积神经网络基本部件21 2.1 “端到端”思想  21 2.2 网络符号定义  . 23 2.3 卷积层  . 24 2.3.1 什么是卷积  24 2.3.2 卷积操作的作用  27 2.4 汇合层  . 28 2.4.1 什么是汇合  29 2.4.2 汇合操作的作用  30 2.5 激活函数  31 2.6 全连接层  33 2.7 目标函数  34 2.8 小结  . 34 3 卷积神经网络经典结构35 3.1 CNN 网络结构中的重要概念  . 35 3.1.1 感受野  . 35 3.1.2 分布式表示  37 3.1.3 深度特征的层次性  39 3.2 经典网络案例分析  . 42 3.2.1 Alex-Net 网络模型  . 42 3.2.2 VGG-Nets 网络模型  46 3.2.3 Network-In-Network  48 3.2.4 残差网络模型  . 49 3.3 小结  . 54 4 卷积神经网络的压缩56 4.1 低秩近似  58 4.2 剪枝与稀疏约束  60 4.3 参数量化  64 4.4 二值网络  68 4.5 知识蒸馏  71 4.6 紧凑的网络结构  74 4.7 小结  . 76 第三部分实践应用篇77 5 数据扩充78 5.1 简单的数据扩充方式  . 78 5.2 特殊的数据扩充方式  . 80 5.2.1 Fancy PCA  . 80 5.2.2 监督式数据扩充  80 5.3 小结  . 82 6 数据预处理83 7 网络参数初始化85 7.1 全零初始化  . 86 7.2 随机初始化  . 86 7.3 其他初始化方法  90 7.4 小结  . 90 8 激活函数91 8.1 Sigmoid 型函数  . 92 8.2 tanh(x) 型函数  . 93 8.3 修正线性单元（ReLU）  93 8.4 Leaky ReLU  . 94 8.5 参数化ReLU  95 8.6 随机化ReLU  97 8.7 指数化线性单元（ELU）  . 98 8.8 小结  . 99 9 目标函数100 9.1 分类任务的目标函数  . 100 9.1.1 交叉熵损失函数  101 9.1.2 合页损失函数  . 101 9.1.3 坡道损失函数  . 101 9.1.4 大间隔交叉熵损失函数  103 9.1.5 中心损失函数  . 105 9.2 回归任务的目标函数  . 107 9.2.1 ?1 损失函数  108 9.2.2 ?2 损失函数  108 9.2.3 Tukey’s biweight 损失函数  109 9.3 其他任务的目标函数  . 109 9.4 小结  . 111 10 网络正则化113 10.1 ?2 正则化  114 10.2 ?1 正则化  115 10.3 *大范数约束  . 115 10.4 随机失活  116 10.5 验证集的使用  . 118 10.6 小结  . 119 11 超参数设定和网络训练120 11.1 网络超参数设定  120 11.1.1 输入数据像素大小  120 11.1.2 卷积层参数的设定  121 11.1.3 汇合层参数的设定  122 11.2 训练技巧  123 11.2.1 训练数据随机打乱  123 11.2.2 学习率的设定  . 123 11.2.3 批规范化操作  . 125 11.2.4 网络模型优化算法选择  127 11.2.5 微调神经网络  . 132 11.3 小结  . 133 12 不平衡样本的处理135 12.1 数据层面处理方法  . 136 12.1.1 数据重采样  136 12.1.2 类别平衡采样  . 137 12.2 算法层面处理方法  . 138 12.2.1 代价敏感方法  . 139 12.2.2 代价敏感法中权重的指定方式  140 12.3 小结  . 142 13 模型集成方法143 13.1 数据层面的集成方法  . 143 13.1.1 测试阶段数据扩充  143 13.1.2 “简易集成”法  144 13.2 模型层面的集成方法  . 144 13.2.1 单模型集成  144 13.2.2 多模型集成  146 13.3 小结  . 149 14 深度学习开源工具简介151 14.1 常用框架对比  . 151 14.2 常用框架的各自特点  . 153 14.2.1 Caffe  153 14.2.2 Deeplearning4j  . 153 14.2.3 Keras  154 14.2.4 MXNet  . 155 14.2.5 MatConvNet  155 14.2.6 TensorFlow  . 155 14.2.7 Theano  . 156 14.2.8 Torch  157 A 向量、矩阵及其基本运算158 B 随机梯度下降162 C 链式法则165 参考文献167 索引181
