高性能嵌入式计算-(英文版.第2版) PDF下载 沃尔夫 百度云 电子书 下载 电子书下载
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711149930
PDF电子书下载不求人，看这篇文章就够了→ http://www.chendianrong.com/pdf#711149930
<p>书名:高性能嵌入式计算-(英文版.第2版)</p><p>作者:沃尔夫</p><p>页数:484</p><p>定价:¥79.0</p><p>出版社:机械工业出版社</p><p>出版日期:2015-05-01</p><p>ISBN:9787111499305</p><p><h2>本书特色</h2></p>[<p>
《高性能嵌入式计算(英文版第2版)》经过全面更新和扩展，涵盖了现代高性能嵌入式系统设计领域使用的广泛技术。现在智能手机、飞机、汽车、电力设备、医疗设备等许多应用都在使用嵌入式多处理器，所以让系统设计人员理解这些复杂技术必须依赖越来越复杂的硬件、软件和设计方法是非常重要的。
　　玛里琳·沃尔夫教授采用一种独特的量化方法来论述现代嵌入式计算系统的设计，解释如何定义和实现性能、功耗和成本的量化目标。贯穿全书的实际应用使得本书对专业人员、研究人员和学生来说都是及时且非常有价值的资源。
　　第2版主要特点：包含全新的一章，讨论信息物理系统(cps)——将控制理论和嵌入式计算相结合的新兴智能系统。
　　讨论嵌入式计算的高级主题。包括针对嵌入式系统的热感知设计、可配置处理器、实时约束和功耗的软件优化、异构多处理器和嵌入式中间件。
　　深入讨论网络、可重配置系统、软硬件协同设计、安全和程序分析。
                                        </p>]<p><h2>作者简介</h2></p>[<p>玛里琳·沃尔夫(MarilynWolf)佐治亚理工学院教授，佐治亚研究联合会优秀学者。她分别于1980年、1981年和1984年获得斯坦福大学电子工程学士学位、硕士学位和博士学位。1984年至1989年任职于贝尔实验室。1989年至2007年执教于普林斯顿大学。她是IEEE和ACM会士、IEEE计算机协会核心成员以及ASEE和SPIE成员。她于2003年获得ASEEFrederickE．Terman奖，于2006年获得IEEE电路与系统教育奖。她的研究兴趣主要包括嵌入式计算、嵌入式视频和计算机视觉、VLSI系统。</p>]<p><h2>目录</h2></p>
    preface to the second editionpreface to the first editionacknowledgmentschapter 1  embedded computing  1.1. the landscape of high-performance embedded computing  1.2. cyber-physical systems and embedded computing    1.2.1. vehicle control and operation    1.2.2. medical devices and systems    1.2.3. electric power    1.2.4. radio and networking    1.2.5. multimedia  1.3. design methodologies    1.3.1. why use design methodologies?    1.3.2. design goals    1.3.3. basic design methodologies    1.3.4. embedded system design flows    1.3.5. standards-based design methodologies    1.3.6. design verification and validation    1.3.7. a methodology of methodologies    1.3.8. joint algorithm and architecture development  1.4. models of computation    1.4.1. why study models of computation?    1.4.2. the turing machine    1.4.3. stream-oriented models    1.4.4. representations of state and control    1.4.5. parallelism and communication    1.4.6. sources and uses of parallelism  1.5. reliability. safety. and security    1.5.1. why reliable embedded systems?    1.5.2. fundamentals of reliable system design    1.5.3. novel attacks and countermeasures  1.6. consumer electronics architectures    1.6.1. bluetooth    1.6.2. wifi    1.6.3. networked consumer devices    1.6.4. high-level services  1.7. summary and a look ahead  what we learned  further reading  questions  lab exerciseschapter 2  cpus  2.1. introduction  2.2. comping processors    2.2.1. evaluating processors    2.2.2. ataxonomy of processors    2.2.3. embedded vs. general-purpose processors  2.3. risc processors and digital signal processors    2.3.1. risc processors    2.3.2. digital signal processors  2.4. parallel execution mechanisms    2.4.1. very long instruction word processors    2.4.2. superscalar processors    2.4.3. simd and vector processors    2.4.4. thread-level parallelism    2.4.5. gpus    2.4.6. processor resource utilization  2.5. variable-performance cpu architectures    2.5.1. dynamic voltage and frequency scaling    2.5.2. reliability and error-aware computing  2.6. processor memory hierarchy    2.6.1. memory component models    2.6.2. register files    2.6.3. caches    2.6.4. scratch pad memory  2.7. encoding and security    2.7.1. code compression    2.7.2. code and data compression    2.7.3. low-power bus encoding    2.7.4. security  2.8. cpu simulation    2.8.1. trace-based analysis    2.8.2. direct execution    2.8.3. microarchitecture-modeling simulators    2.8.4. power and thermal simulation and modeling  2.9. automated cpu design    2.9.1. configurable processors    2.9.2. instruction set synthesis  2.10. summary  what we learned  further reading  questions  lab exerciseschapter 3  programs  3.1. introduction  3.2. code generation and back-end compilation    3.2.1. models for instructions    3.2.2. register allocation    3.2.3. instruction selection and scheduling    3.2.4. code placement    3.2.5. programming environments  3.3. memory-oriented optimizations    3.3.1. loop transformations    3.3.2. global optimizations    3.3.3. buffer. data transfer. and storage management    3.3.4. cache- and scratch pad-oriented optimizations    3.3.5. main memory-oriented optimizations  3.4. program performance analysis    3.4.1. performance models    3.4.2. path analysis    3.4.3. path timing  3.5. models of computation and programming    3.5.1. interrupt-oriented languages    3.5.2. data flow languages    3.5.3. control-oriented languages    3.5.4. java    3.5.5. heterogeneous models of computation  3.6. summary  what we have learned  further reading  questions  lab exerciseschapter 4  processes and operating systems  4.1. introduction  4.2. real-time process scheduling    4.2.1. preliminaries    4.2.2. real-time scheduling algorithms    4.2.3. multi-criticality scheduling    4.2.4. scheduling for dynamic voltage and frequenc5 scaling    4.2.5. performance estimation  4.3. languages and scheduling  4.4. operating system design    4.4.1. memory management in embedded operating systems    4.4.2. structure of a real-time operating system    4.4.3. operating system overhead    4.4.4. support for scheduling    4.4.5. interprocess communication mechanisms    4.4.6. power management    4.4.7. file systems in embedded devices  4.5. verification  4.6. summary  what we have learned  further reading  questions  lab exerciseschapter 5  multiprocessor architectures  5.1. introduction  5.2. why embedded multiprocessors?    5.2.1. requirements on embedded systems    5.2.2. performance and energy    5.2.3. specialization and multiprocessors    5.2.4. flexibility and efficiency  5.3. multiprocessor design techniques    5.3.1. multiprocessor design methodologies    5.3.2. multiprocessor modeling and simulation  5.4. multiprocessor architectures  5.5. processing elements  5.6. interconnection networks    5.6.1. models    5.6.2. network topologies    5.6.3. routing and flow control    5.6.4. networks-on-chips  5.7. memory systems    5.7.1. traditional parallel memory systems    5.7.2. models for memory    5.7.3. heterogeneous memory systems    5.7.4. consistent parallel memory systems  5.8. physically distributed systems and networks    5.8.1. can bus    5.8.2. time-triggered architecture    5.8.3. flexray    5.8.4. aircraft networks  5.9. multiprocessor design methodologies and algorithms  5.10. summary  what we have learned  further reading  questions  lab exerciseschapter 6  multiprocessor software  6.1. introduction  6.2. what is different about embedded multiprocessor software?  6.3. real-time multiprocessor operating systems    6.3.1. role of the operating system    6.3.2. multiprocessor scheduling    6.3.3. scheduling with dynamic tasks  6.4. services and middleware for embedded multiprocessors    6.4.1. standards-based services    6.4.2. system-on-chip services    6.4.3. quality of service  6.5. design verification  6.6. summary  what we have learned  further reading  questions  lab exerciseschapter 7  system-level design and hardware/software  co-design  7.1. introduction  7.2. performance estimation    7.2.1. high-level synthesis    7.2.2. accelerator estimation  7.3. hardware/software co-synthesis algorithms    7.3.1. program representations    7.3.2. platform representations    7.3.3. template-driven synthesis algorithms    7.3.4. co-synthesis of general multiprocessors    7.3.5. multi-objective optimization    7.3.6. control and i/o synthesis    7.3.7. memory systems    7.3.8. co-synthesis for reconfigurable systems  7.4. electronic system-level design  7.5. thermal-aware design  7.8. reliability  7.7. system-level simulation  7.8. summary  what we have learned  further reading  questions  lab exerciseschapter 8  cyber-physical systems  8.1. introduction  8.2. control theory and systems  8.3. control/computing co-design  8.4. networked control systems  8.5. design methodologies    8.5.1. model-based design    8.5.2. formal methods  8.8. security  8.7. summary  what we have learned  further reading  questions  lab exercisesglossaryreferencesindex
